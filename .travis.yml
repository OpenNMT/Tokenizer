dist: bionic
language: cpp
compiler:
  - gcc
  - clang
env:
  global:
    - SENTENCEPIECE_VERSION="0.1.8"
cache:
  directories:
    - $HOME/sentencepiece-$SENTENCEPIECE_VERSION/
before_install:
  - export ROOT_TRAVIS_DIR=$(pwd)
  - |
    if [ ! -d $HOME/sentencepiece-$SENTENCEPIECE_VERSION/lib ]; then
      wget https://github.com/google/sentencepiece/archive/v$SENTENCEPIECE_VERSION.tar.gz
      tar xf v$SENTENCEPIECE_VERSION.tar.gz
      cd sentencepiece-$SENTENCEPIECE_VERSION
      mkdir build
      cd build
      cmake -DCMAKE_INSTALL_PREFIX=$HOME/sentencepiece-$SENTENCEPIECE_VERSION ..
      make
      make install
      cd $ROOT_TRAVIS_DIR
    fi
install:
  - export TOKENIZER_ROOT=$HOME/Tokenizer
  - export SENTENCEPIECE_ROOT=$HOME/sentencepiece-$SENTENCEPIECE_VERSION
  - mkdir build && cd build
  - cmake -DBUILD_TESTS=ON -DCMAKE_INSTALL_PREFIX=$TOKENIZER_ROOT -DCMAKE_PREFIX_PATH=$SENTENCEPIECE_ROOT ..
  - make install
  - cd $ROOT_TRAVIS_DIR
script:
  - build/test/onmt_tokenizer_test test/data

matrix:
  include:
    - name: Python tests
      language: python
      python:
        - "3.6"
      env:
        - TWINE_REPOSITORY_URL="https://upload.pypi.org/legacy/"
      services:
        - docker
      before_install:
        - docker pull quay.io/pypa/manylinux1_x86_64
        - docker run -v $PWD:/root -w /root quay.io/pypa/manylinux1_x86_64 bash /root/bindings/python/tools/build_wheel.sh
        - pip install pytest twine
        - pip install torch==1.2.0+cpu torchvision==0.4.0+cpu -f https://download.pytorch.org/whl/torch_stable.html
      install:
        - pip install wheelhouse/*36*.whl
      script:
        - pytest bindings/python/test/test.py
      after_success:
        - |
              if [[ -n $TRAVIS_TAG ]]; then
                  twine upload wheelhouse/*.whl
              fi
